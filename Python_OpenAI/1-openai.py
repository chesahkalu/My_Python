#!/usr/bin/python3

import openai
import os
#openai.api_key = "sk-.....V"

"""to use .env file"""
from dotenv import load_dotenv 
load_dotenv()
openai.api_key  = os.getenv('OPENAI_API_KEY')

def get_completion(prompt, model="gpt-3.5-turbo"): # gpt-3.5-turbo is the default model
    messages = [{"role": "user", "content": prompt}] # prompt is the message sent by the user, role is the role of the message sender, content is the message sent by the user, 
    response = openai.ChatCompletion.create(    # ChatCompletion is the endpoint, create is the method
        model=model,                            # The model argument specifies the model to use for completion. The default model is the ada model.
        messages=messages,                      # The messages argument is a list of messages that have been exchanged in the conversation so far. Each message is a dictionary with two keys: role and content. The role key specifies the role of the message sender, and the content key specifies the message content.
        temperature=0,                          # The temperature argument controls the degree of randomness in the response generated by the model. The higher the temperature, the more random the response. The lower the temperature, the more predictable the response. The default temperature is 0.7 and 0 for a basic realistic chatbot.
    )
    return response.choices[0].message["content"]   # The response.choices[0].message["content"] returns the message sent by the AI

"""Using openAi API, we can write codes that can use the AI large language model to perform various tasks.
This tasks can be designed as a simple prompt, which will be sent to the AI model, and the model will respond with a completion.
The prompt can serve the purposse of what a long code would do, but in a more simple way.

Also we can use the API to create a chatbot, which will be able to respond to messages sent by the user.

The above code is a simple example of how to creat a connection to the API using and API key. 
Import to set the key as an environment variable, so that it is not visible to the public.

The get_completion function is a simple function that takes a prompt as an argument, and returns the response from the AI model.

https://github.com/dsdanielpark/Bard-API  - for bard API
"""
